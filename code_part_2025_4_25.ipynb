{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9cF0OLjg1HF"
      },
      "outputs": [],
      "source": [
        "# 基础数据探索\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 加载数据集\n",
        "taobao_ad_data = pd.read_csv('round1_ijcai_18_train_20180301F.csv')\n",
        "\n",
        "#显示数据集前10行\n",
        "taobao_ad_data.head(10)\n",
        "\n",
        "#显示每列的数据类型\n",
        "taobao_ad_data.dtypes\n",
        "\n",
        "#显示共有几行几列\n",
        "taobao_ad_data.shape\n",
        "\n",
        "# 统计至少包含一个-1的总行数\n",
        "rows_with_minus_one = (taobao_ad_data == -1).any(axis=1).sum()\n",
        "print(f\"\\n数据中至少包含一个-1的总行数: {rows_with_minus_one}\")\n",
        "print(f\"占总行数的比例: {rows_with_minus_one/len(taobao_ad_data):.2%}\")\n",
        "\n",
        "# 删除包含-1的行\n",
        "clean_data = taobao_ad_data[~(taobao_ad_data == -1).any(axis=1)].copy()\n",
        "\n",
        "# 重建连续索引\n",
        "clean_data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# 验证结果\n",
        "print(f\"清理后行数: {len(clean_data)}\")\n",
        "clean_data.shape\n",
        "\n",
        "# 定义需要保留的列\n",
        "selected_columns = [\n",
        "    'item_id',\n",
        "    'item_category_list',\n",
        "    'item_brand_id',\n",
        "    'item_city_id',\n",
        "    'item_price_level',\n",
        "    'item_sales_level',\n",
        "    'item_collected_level',\n",
        "    'item_pv_level',\n",
        "    'user_gender_id',\n",
        "    'user_age_level',\n",
        "    'user_star_level',\n",
        "    'context_timestamp',\n",
        "    'context_page_id',\n",
        "    'predict_category_property',\n",
        "    'shop_review_positive_rate',\n",
        "    'shop_score_service',\n",
        "    'shop_score_delivery',\n",
        "    'shop_score_description',\n",
        "    'is_trade'\n",
        "]\n",
        "\n",
        "# 筛选列\n",
        "filtered_data = clean_data[selected_columns]\n",
        "\n",
        "# 检查数据\n",
        "filtered_data.head(10)\n",
        "\n",
        "# 拆分item_category_list\n",
        "filtered_data[['category_0', 'category_1', 'category_2']] = (\n",
        "    filtered_data['item_category_list'].str.split(';', expand=True))\n",
        "\n",
        "# 时间特征提取\n",
        "filtered_data['timestamp'] = pd.to_datetime(filtered_data['context_timestamp'], unit='s')\n",
        "filtered_data['hour'] = filtered_data['timestamp'].dt.hour\n",
        "filtered_data['is_weekend'] = filtered_data['timestamp'].dt.weekday >= 5\n",
        "\n",
        "# 检查predict_category_property是否包含商品类目\n",
        "filtered_data['category_match'] = filtered_data.apply(\n",
        "    lambda row: str(row['category_1']) in str(row['predict_category_property']), axis=1)\n",
        "\n",
        "filtered_data['item_id'] = filtered_data['item_id'].astype('category')\n",
        "# 检查数据\n",
        "filtered_data.head(10)\n",
        "\n",
        "null_ratio = filtered_data['category_2'].isnull().mean()\n",
        "print(f\"category_2 空值比例: {null_ratio:.2%}\")\n",
        "\n",
        "# 删除 category_2 列（直接操作）\n",
        "filtered_data.drop('category_2', axis=1, inplace=True)\n",
        "\n",
        "# 1. 删除已拆分的多值字段\n",
        "filtered_data.drop('item_category_list', axis=1, inplace=True)\n",
        "\n",
        "# 2. 时间戳处理（选择性删除）\n",
        "if 'timestamp' in filtered_data.columns:  # 确保已生成timestamp列\n",
        "    filtered_data.drop('context_timestamp', axis=1, inplace=True)\n",
        "# 检查数据\n",
        "filtered_data.head(10)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 选择数值型特征\n",
        "num_cols = ['item_price_level', 'item_sales_level', 'item_collected_level', 'item_pv_level']\n",
        "filtered_data[num_cols].hist(bins=20, figsize=(12, 6))\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 检查二级类目（category_1）的分布\n",
        "top_categories = filtered_data['category_1'].value_counts().nlargest(20)  # 取前20（因类目可能较多）\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=top_categories.index, y=top_categories.values, palette=\"viridis\")\n",
        "plt.xticks(rotation=45, ha='right')  # 调整标签角度\n",
        "plt.title('Top_20_Secondary_category_distribution（category_1）')\n",
        "plt.ylabel('sample_size') # 样本数量\n",
        "plt.tight_layout()  # 避免标签重叠\n",
        "plt.show()\n",
        "\n",
        "# 打印类目数量和占比\n",
        "print(f\"二级类目总数: {filtered_data['category_1'].nunique()}\")\n",
        "print(\"Top 5 二级类目占比:\")\n",
        "print((top_categories.head(5) / len(filtered_data)).round(4))\n",
        "\n",
        "# 1. 获取TOP5类目\n",
        "top_5_categories = filtered_data['category_1'].value_counts().nlargest(5).index\n",
        "\n",
        "# 2. 合并非TOP5类目为\"other\"\n",
        "filtered_data['category_1'] = filtered_data['category_1'].apply(\n",
        "    lambda x: x if x in top_5_categories else 'other'\n",
        ")\n",
        "\n",
        "# 3. 检查结果\n",
        "print(\"合并后的类目分布:\")\n",
        "print(filtered_data['category_1'].value_counts(normalize=True))\n",
        "\n",
        "# 4. 检查TOP5类目的转化率\n",
        "print(\"\\nTOP5类目转化率:\")\n",
        "print(filtered_data.groupby('category_1')['is_trade'].mean().sort_values(ascending=False))\n",
        "\n",
        "# 1. 计算数值特征与目标的相关性\n",
        "num_cols = ['item_price_level', 'item_sales_level', 'item_collected_level', 'item_pv_level']\n",
        "corr_series = filtered_data[num_cols + ['is_trade']].corr()['is_trade'].drop('is_trade')\n",
        "\n",
        "# 2. 按相关性绝对值排序（从高到低）\n",
        "corr_series = corr_series.sort_values(key=abs, ascending=False)\n",
        "\n",
        "# 3. 绘制横向条形图\n",
        "plt.figure(figsize=(10, 4))\n",
        "bars = plt.barh(corr_series.index, corr_series.values, color='steelblue')\n",
        "\n",
        "# 4. 添加数值标签\n",
        "for bar in bars:\n",
        "    width = bar.get_width()\n",
        "    plt.text(width if width > 0 else width,  # 标签位置\n",
        "            bar.get_y() + bar.get_height()/2,  # 垂直居中\n",
        "            f'{width:.3f}',  # 保留3位小数\n",
        "            va='center', ha='left' if width > 0 else 'right',\n",
        "            fontsize=10)\n",
        "\n",
        "# 5. 图表修饰\n",
        "plt.title('Numerical Features Correlation with is_trade', fontweight='bold')\n",
        "plt.xlabel('Correlation Coefficient')\n",
        "plt.xlim(-0.15, 0.15)  # 根据实际数据调整范围\n",
        "plt.axvline(0, color='gray', linestyle='--', linewidth=0.8)\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 计算各价格等级的转化率\n",
        "price_conversion = filtered_data.groupby('item_price_level')['is_trade'].mean().sort_values(ascending=False)\n",
        "\n",
        "# 创建图形\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# 创建条形图（使用seaborn的默认样式）\n",
        "ax = sns.barplot(x=price_conversion.index,\n",
        "                y=price_conversion.values,\n",
        "                color='steelblue')  # 使用固定颜色替代渐变色\n",
        "\n",
        "# 添加数值标签\n",
        "for i, v in enumerate(price_conversion.values):\n",
        "    ax.text(i, v + 0.005, f\"{v:.3f}\",  # 保留3位小数\n",
        "            ha='center',\n",
        "            va='bottom',\n",
        "            fontsize=10)\n",
        "\n",
        "# 设置图表标题和标签\n",
        "plt.title('Conversion Rate by Price Level', fontsize=14, pad=20)\n",
        "plt.xlabel('Price Level', fontsize=12)\n",
        "plt.ylabel('Conversion Rate', fontsize=12)\n",
        "\n",
        "# 调整坐标轴\n",
        "plt.ylim(0, price_conversion.max() * 1.2)  # 留出空间显示标签\n",
        "plt.xticks(rotation=0)  # 保持水平标签\n",
        "\n",
        "# 显示网格线\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 1.1 用户性别与商品类别的交互\n",
        "filtered_data['gender_category'] = filtered_data['user_gender_id'].astype(str) + '_' + filtered_data['category_1'].astype(str)\n",
        "\n",
        "# 1.2 用户年龄段与价格敏感度\n",
        "filtered_data['age_price_ratio'] = filtered_data['user_age_level'] / (filtered_data['item_price_level'] + 1)\n",
        "\n",
        "# 2.1 商品销量与店铺评分的综合指标\n",
        "filtered_data['sales_service_score'] = filtered_data['item_sales_level'] * filtered_data['shop_score_service']\n",
        "\n",
        "# 2.2 商品被收藏与店铺物流评分的交互\n",
        "filtered_data['collect_delivery_score'] = filtered_data['item_collected_level'] * filtered_data['shop_score_delivery']\n",
        "\n",
        "# 3.1 时段与类目的交互\n",
        "filtered_data['hour_category'] = filtered_data['hour'].astype(str) + '_' + filtered_data['category_1'].astype(str)\n",
        "\n",
        "# 3.2 是否周末与商品价格等级\n",
        "filtered_data['weekend_price'] = filtered_data['is_weekend'].astype(int) * filtered_data['item_price_level']\n",
        "\n",
        "# 1.1 类目平均价格等级（用当前数据近似）\n",
        "category_avg_price = filtered_data.groupby('category_1')['item_price_level'].mean().to_dict()\n",
        "filtered_data['category_avg_price'] = filtered_data['category_1'].map(category_avg_price)\n",
        "\n",
        "# 1.2 类目竞争度（同类商品数量）\n",
        "category_competition = filtered_data['category_1'].value_counts().to_dict()\n",
        "filtered_data['category_competition'] = filtered_data['category_1'].map(category_competition)\n",
        "\n",
        "# 2.1 用用户星级模拟活跃度\n",
        "filtered_data['user_activeness'] = filtered_data['user_star_level'] / filtered_data['user_star_level'].max()\n",
        "\n",
        "# 2.2 用商品曝光等级模拟点击率\n",
        "filtered_data['simulated_ctr'] = filtered_data['item_pv_level'] / filtered_data['item_pv_level'].max()\n",
        "\n",
        "\n",
        "# 对高基数文本列进行频数编码（比LabelEncoding更适合树模型）\n",
        "for col in ['predict_category_property', 'category_0', 'category_1', 'gender_category', 'hour_category']:\n",
        "    if col in filtered_data.columns:\n",
        "        # 频数编码：用出现频率代替原始值\n",
        "        freq_encoder = filtered_data[col].value_counts(normalize=True)\n",
        "        filtered_data[col+'_freq'] = filtered_data[col].map(freq_encoder)\n",
        "        filtered_data.drop(col, axis=1, inplace=True)\n",
        "\n",
        "# 时间戳特征增强（已存在hour列的情况下补充更多时间特征）\n",
        "if 'timestamp' in filtered_data.columns:\n",
        "    filtered_data['day_of_week'] = filtered_data['timestamp'].dt.dayofweek  # 周一=0，周日=6\n",
        "    filtered_data['is_morning'] = filtered_data['hour'].between(6, 12).astype(int)\n",
        "    filtered_data.drop('timestamp', axis=1, inplace=True)\n",
        "\n",
        "# 将bool类型显式转换为int\n",
        "bool_cols = ['is_weekend', 'category_match']\n",
        "for col in bool_cols:\n",
        "    if col in filtered_data.columns:\n",
        "        filtered_data[col] = filtered_data[col].astype(int)\n",
        "\n",
        "# 删除可能重复的列（如原始ID列已被编码）\n",
        "cols_to_drop = [col for col in ['item_id', 'item_brand_id', 'category_1']\n",
        "               if col in filtered_data.columns]\n",
        "filtered_data.drop(cols_to_drop, axis=1, inplace=True)\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# 确保目标列是int类型\n",
        "filtered_data['is_trade'] = filtered_data['is_trade'].astype(int)\n",
        "\n",
        "# 分割特征和目标\n",
        "X = filtered_data.drop('is_trade', axis=1)\n",
        "y = filtered_data['is_trade']\n",
        "\n",
        "# 检查最终特征类型\n",
        "print(\"最终特征类型：\\n\", X.dtypes)\n",
        "\n",
        "# 训练模型\n",
        "model = LGBMClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "# 可视化特征重要性\n",
        "plt.figure(figsize=(10,6))\n",
        "(pd.Series(model.feature_importances_, index=X.columns)\n",
        " .nlargest(20)\n",
        " .plot.barh(title='Top 20 Feature Importance'))\n",
        "plt.show()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# 划分训练集和测试集（保持正负样本比例）\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.3,\n",
        "    stratify=y,  # 保持类别比例\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 1. 清理无效特征（必须步骤）\n",
        "X_train_clean = X_train.drop(columns=[X_train.columns[0], 'category_0_freq'], errors='ignore')\n",
        "\n",
        "# 2. 设置针对不平衡数据的参数\n",
        "model = LGBMClassifier(\n",
        "    # 核心不平衡处理参数\n",
        "    scale_pos_weight=318322/6188,  # 负样本数/正样本数 ≈ 51.4\n",
        "    class_weight='balanced',\n",
        "\n",
        "    # 结构调整\n",
        "    num_leaves=15,           # 减少叶子数量（防止过拟合少数类）\n",
        "    max_depth=3,             # 限制树深度\n",
        "    min_data_in_leaf=100,    # 增加叶子最小样本量\n",
        "\n",
        "    # 训练控制\n",
        "    learning_rate=0.05,      # 降低学习率\n",
        "    n_estimators=500,        # 增加树数量\n",
        "    reg_alpha=0.1,           # L1正则化\n",
        "    reg_lambda=0.1,          # L2正则化\n",
        "    verbosity=-1             # 关闭警告\n",
        ")\n",
        "\n",
        "# 3. 训练模型\n",
        "model.fit(X_train_clean, y_train)\n",
        "\n",
        "# 4. 检查特征重要性（验证是否正常工作）\n",
        "pd.Series(\n",
        "    model.feature_importances_,\n",
        "    index=X_train_clean.columns\n",
        ").nlargest(20).plot.barh(title='Feature Importance')\n",
        "\n",
        "# 检查模型是否学到有效模式\n",
        "y_pred_proba = model.predict_proba(X_train_clean)[:, 1]\n",
        "print(\"训练集AUC:\", roc_auc_score(y_train, y_pred_proba))\n",
        "\n",
        "# 如果AUC>0.7说明模型有效\n",
        "\n",
        "# 1. 对测试集进行相同的特征清理（关键步骤！）\n",
        "X_test_clean = X_test.drop(columns=[X_test.columns[0], 'category_0_freq'], errors='ignore')\n",
        "\n",
        "# 2. 预测测试集概率（注意使用X_test_clean）\n",
        "y_pred_proba_test = model.predict_proba(X_test_clean)[:, 1]\n",
        "\n",
        "# 3. 处理极端概率值避免log(0)\n",
        "y_pred_proba_test = np.clip(y_pred_proba_test, 1e-15, 1-1e-15)\n",
        "\n",
        "# 4. 计算LogLoss\n",
        "logloss = log_loss(y_test, y_pred_proba_test)\n",
        "print(f\"\"\"\n",
        "=== 测试集评估 ===\n",
        "LogLoss: {logloss:.4f}\n",
        "评估标准:\n",
        "  <0.3 : 优秀\n",
        "  0.3-0.5 : 合格\n",
        "  >0.5 : 需改进\n",
        "\"\"\")\n",
        "\n",
        "# 创建评分分箱 (0-1区间，每0.1一个区间)\n",
        "filtered_data['service_bin'] = pd.cut(\n",
        "    filtered_data['shop_score_service'],\n",
        "    bins=[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "    labels=False\n",
        ")\n",
        "\n",
        "# 计算每个分箱的转化率\n",
        "conversion_by_service = filtered_data.groupby('service_bin')['is_trade'].agg(\n",
        "    count='count',\n",
        "    conversions='sum',\n",
        "    conversion_rate='mean'\n",
        ").reset_index()\n",
        "\n",
        "print(conversion_by_service)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(\n",
        "    conversion_by_service['service_bin'] * 0.1 + 0.05,  # 取分箱中点\n",
        "    conversion_by_service['conversion_rate'],\n",
        "    marker='o'\n",
        ")\n",
        "plt.xlabel('Shop Service Score (0.1 intervals)')\n",
        "plt.ylabel('Conversion Rate')\n",
        "plt.title('Conversion Rate by Service Score')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 单变量逻辑回归\n",
        "X = filtered_data[['sales_service_score']]\n",
        "y = filtered_data['is_trade']\n",
        "\n",
        "model = LogisticRegression(class_weight='balanced')\n",
        "model.fit(X, y)\n",
        "\n",
        "# 计算每增加1分的几率比(Odds Ratio)\n",
        "import numpy as np\n",
        "odds_ratio = np.exp(model.coef_[0][0])  # 取指数得到OR\n",
        "print(f\"销售服务评分每增加1分，转化几率变为原来的 {odds_ratio:.2f} 倍\")\n",
        "\n",
        "# 分段统计转化率\n",
        "hourly_conversion = filtered_data.groupby('hour')['is_trade'].agg(\n",
        "    count='count',\n",
        "    conversions='sum',\n",
        "    conversion_rate='mean'\n",
        ").reset_index()\n",
        "\n",
        "# 逻辑回归量化影响\n",
        "X_hour = filtered_data[['hour']]\n",
        "y = filtered_data['is_trade']\n",
        "hour_model = LogisticRegression(class_weight='balanced')\n",
        "hour_model.fit(X_hour, y)\n",
        "hour_effect = np.exp(hour_model.coef_[0][0])  # 每增加1小时的几率比\n",
        "\n",
        "print(f\"每多浏览1小时，转化几率变为原来的 {hour_effect:.2f} 倍\")\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "# 实际转化率曲线\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(hourly_conversion['hour'], hourly_conversion['conversion_rate'],\n",
        "         marker='o', color='#4E79A7')\n",
        "plt.xlabel('Browsing duration (hours)')\n",
        "plt.ylabel('Conversion rate')\n",
        "plt.title('Hourly conversion rate change')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 逻辑回归预测曲线\n",
        "plt.subplot(1, 2, 2)\n",
        "hour_range = np.arange(0, 25).reshape(-1, 1)\n",
        "plt.plot(hour_range, hour_model.predict_proba(hour_range)[:, 1],\n",
        "         color='#E15759', lw=2)\n",
        "plt.xlabel('Browsing duration (hours)')\n",
        "plt.ylabel('Predicting transformation probability')\n",
        "plt.title(f'Every +1 hour: {hour_effect:.2f}xchance')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 按评分分箱（每0.5分一个区间）\n",
        "filtered_data['delivery_bin'] = pd.cut(\n",
        "    filtered_data['collect_delivery_score'],\n",
        "    bins=np.arange(0, 5.5, 0.5)\n",
        ")\n",
        "\n",
        "delivery_conversion = filtered_data.groupby('delivery_bin')['is_trade'].agg(\n",
        "    count='count',\n",
        "    conversion_rate='mean'\n",
        ").reset_index()\n",
        "\n",
        "# 逻辑回归\n",
        "X_delivery = filtered_data[['collect_delivery_score']]\n",
        "delivery_model = LogisticRegression(class_weight='balanced')\n",
        "delivery_model.fit(X_delivery, y)\n",
        "delivery_effect = np.exp(delivery_model.coef_[0][0])\n",
        "\n",
        "print(f\"快递评分每+1分，转化几率变为 {delivery_effect:.2f} 倍\")\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# 分箱转化率柱状图\n",
        "plt.subplot(1, 2, 1)\n",
        "delivery_conversion['mid'] = delivery_conversion['delivery_bin'].apply(lambda x: x.mid)\n",
        "plt.bar(delivery_conversion['mid'], delivery_conversion['conversion_rate'],\n",
        "        width=0.4, color='#59A14F', alpha=0.7)\n",
        "plt.xlabel('Courier service score')\n",
        "plt.ylabel('Conversion rate')\n",
        "plt.title('Actual conversion rate of different scoring intervals')\n",
        "\n",
        "# 边际效应曲线\n",
        "plt.subplot(1, 2, 2)\n",
        "score_range = np.linspace(0, 5, 100).reshape(-1, 1)\n",
        "plt.plot(score_range, delivery_model.predict_proba(score_range)[:, 1],\n",
        "         color='#F28E2B', lw=2)\n",
        "plt.xlabel('Courier service score')\n",
        "plt.ylabel('Predicting transformation probability')\n",
        "plt.title(f'Every +1 point: {delivery_effect:.2f}xchance')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ]
}